{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda\\lib\\site-packages (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp39-cp39-win_amd64.whl (167.2 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda\\lib\\site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the json file\n",
      "processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorne\\Downloads\\prepare_data.py:61: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataframe is (87599, 6)\n",
      "Done\n",
      "Reading the json file\n",
      "processing...\n",
      "shape of the dataframe is (10570, 5)\n",
      "Done\n",
      "Reading lines...\n",
      "Read 87599 sentence pairs (train)\n",
      "Trimmed to 87063 sentence pairs (train)\n",
      "Read 10570 sentence pairs (valid)\n",
      "Trimmed to 10514 sentence pairs (valid)\n",
      "Counting words...\n",
      "Counted words: 21685\n",
      "keep_words 12800 / 21682 = 0.5904\n",
      "Trimmed from 87063 pairs to 22987, 0.2640 of total\n",
      "Trimmed from 10514 pairs to 6919, 0.6581 of total\n",
      "random sentence ['how many times was american idol nominated for an emmy ?', 'nine']\n",
      "Beginning training for epoch 1\n",
      "Initializing ...\n",
      "Training...\n",
      "Epoch: 1; Iteration: 10; Percent complete: 0.4%; Average loss: 9.1866\n",
      "Epoch: 1; Iteration: 20; Percent complete: 0.8%; Average loss: 7.9834\n",
      "Epoch: 1; Iteration: 30; Percent complete: 1.2%; Average loss: 6.7597\n",
      "Epoch: 1; Iteration: 40; Percent complete: 1.6%; Average loss: 6.5931\n",
      "Epoch: 1; Iteration: 50; Percent complete: 2.0%; Average loss: 6.4788\n",
      "Beginning epoch validation...\n",
      "Epoch 0 validation loss: 6.726680606716497\n",
      "Beginning training for epoch 2\n",
      "Initializing ...\n",
      "Training...\n",
      "Epoch: 2; Iteration: 10; Percent complete: 2.4%; Average loss: 6.3717\n",
      "Epoch: 2; Iteration: 20; Percent complete: 2.8%; Average loss: 6.3108\n",
      "Epoch: 2; Iteration: 30; Percent complete: 3.2%; Average loss: 6.3384\n",
      "Epoch: 2; Iteration: 40; Percent complete: 3.6%; Average loss: 6.2601\n",
      "Epoch: 2; Iteration: 50; Percent complete: 4.0%; Average loss: 6.3071\n",
      "Beginning epoch validation...\n",
      "Epoch 1 validation loss: 6.652078718304095\n",
      "Beginning training for epoch 3\n",
      "Initializing ...\n",
      "Training...\n",
      "Epoch: 3; Iteration: 10; Percent complete: 4.4%; Average loss: 6.2239\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeginning training for epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 57\u001b[0m     \u001b[43mtrain_iterations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\train.py:190\u001b[0m, in \u001b[0;36mtrain_iterations\u001b[1;34m(epoch, model_name, voc, pairs_train, pairs_valid, encoder, decoder, encoder_optimizer, decoder_optimizer, scheduler_encoder, scheduler_decoder, embedding, n_iteration, batch_size, print_every, save_every, corpus_name, teacher_forcing_ratio, num_epochs)\u001b[0m\n\u001b[0;32m    187\u001b[0m input_variable, lengths, target_variable, mask, max_target_len \u001b[38;5;241m=\u001b[39m training_batch\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# Run a training iteration with batch\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_target_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m             \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_LENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m print_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# scheduler_encoder.step()\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# scheduler_decoder.step()\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Print progress\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\train.py:141\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, encoder_optimizer, decoder_optimizer, teacher_forcing_ratio, batch_size, max_length, clip, voc)\u001b[0m\n\u001b[0;32m    137\u001b[0m         n_totals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nTotal\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;66;03m# loss -= criterion(pred, target_variable[t])\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Perform backpropagation)\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# plt.figure()\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# decoder_input = decoder_input.to(device)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Adjust model weights\u001b[39;00m\n\u001b[0;32m    156\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "    \n",
    "import torch.cuda\n",
    "from torch import nn, optim\n",
    "\n",
    "from evaluate import evaluate_input\n",
    "from model import Encoder, Decoder\n",
    "from prepare_data import get_vocab_and_sentence_pairs\n",
    "from train import train_iterations, build_models\n",
    "\n",
    "\n",
    "dataset = 'squad1'\n",
    "\n",
    "voc, pairs_train, pairs_valid = get_vocab_and_sentence_pairs(dataset)\n",
    "\n",
    "randomize = random.choice(pairs_train)\n",
    "print('random sentence {}'.format(randomize))\n",
    "\n",
    "#print number of words\n",
    "input_size = voc.num_words\n",
    "output_size = voc.num_words\n",
    "# print('Input : {} Output : {}'.format(input_size, output_size))\n",
    "\n",
    "############################################\n",
    "#\n",
    "# Note: I did not have the ability to test\n",
    "# this on a GPU-enabled PC, so this might not\n",
    "# work on GPU\n",
    "#\n",
    "############################################\n",
    "\n",
    "batch_size = 128\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_iteration = 50  # 0 means use the whole dataset, otherwise n=50 would take the first 50 of the randomized pairs\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "embedding = nn.Embedding(voc.num_words, embed_size)\n",
    "\n",
    "model_name = 'Simple_model'\n",
    "\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size, embedding, num_layers)\n",
    "decoder = Decoder(hidden_size, voc.num_words, embedding, num_layers)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * 5.0)\n",
    "scheduler_encoder = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, mode='min', patience=5,\n",
    "                                                               factor=0.5, min_lr=0.0000001, verbose=True)\n",
    "scheduler_decoder = torch.optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, mode='min', patience=5,\n",
    "                                                               factor=0.5, min_lr=0.0000001, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Beginning training for epoch {}'.format(epoch + 1))\n",
    "    train_iterations(epoch, model_name, voc, pairs_train, pairs_valid, encoder, decoder, encoder_optimizer,\n",
    "                     decoder_optimizer, scheduler_encoder, scheduler_decoder, embedding, num_iteration, batch_size,\n",
    "                     10, 5, dataset, teacher_forcing_ratio, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the json file\n",
      "processing...\n",
      "shape of the dataframe is (87599, 6)\n",
      "Done\n",
      "Reading the json file\n",
      "processing...\n",
      "shape of the dataframe is (10570, 5)\n",
      "Done\n",
      "Reading lines...\n",
      "Read 87599 sentence pairs (train)\n",
      "Trimmed to 87063 sentence pairs (train)\n",
      "Read 10570 sentence pairs (valid)\n",
      "Trimmed to 10514 sentence pairs (valid)\n",
      "Counting words...\n",
      "Counted words: 21685\n",
      "keep_words 12800 / 21682 = 0.5904\n",
      "Trimmed from 87063 pairs to 22987, 0.2640 of total\n",
      "Trimmed from 10514 pairs to 6919, 0.6581 of total\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3c7b139d4e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                       \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                       \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                       epoch=epoch)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mevaluate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/train.py\u001b[0m in \u001b[0;36mbuild_models\u001b[0;34m(load_filename, hidden_size, encoder_n_layers, decoder_n_layers, batch_size, embedding_size, dataset_name, model_name, iteration, epoch)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_HOME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# If loading on same machine the model was trained on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}_{}_{}.tar'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;31m# If loading a model trained on GPU to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;31m# reset back to the original position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "from train import build_models\n",
    "\n",
    "batch_size = 128\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_iteration = 50  # 0 means use the whole dataset, otherwise n=50 would take the first 50 of the randomized pairs\n",
    "num_epochs = 5\n",
    "learning_rate = 0.0001\n",
    "teacher_forcing_ratio = 0.5\n",
    "dataset='squad1'\n",
    "model_name = 'Simple_model'\n",
    "\n",
    "\n",
    "# reload the checkpoints:\n",
    "iteration = 20  # If testing, change this to whichever iteration showed up last                                    \n",
    "epoch = 35     # likewise for the epoch\n",
    "encoder, decoder, _, _ = build_models(load_filename=True,\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      encoder_n_layers=num_layers,\n",
    "                                      decoder_n_layers=num_layers,\n",
    "                                      batch_size=batch_size,\n",
    "                                      dataset_name=dataset,\n",
    "                                      embedding_size=embed_size,\n",
    "                                      model_name=model_name,\n",
    "                                      iteration=iteration,\n",
    "                                      epoch=epoch)\n",
    "\n",
    "evaluate_input(encoder, decoder, voc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
